{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = \"QM9_129440_MLtraining\"\n",
    "input_file2 = \"QM9_49762_MLtraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features for bps_pred:\n",
      "['#Accept', '#Donor', '#C', '#O/#C', 'SLogP', '#Ether', '#Nitrile', 'apol', '#R=R', '#Ar-N', '#Ring', '#ArR', 'Vabc', '#Ester', '#C=O', '#AlHR', '#ArHR', '#Bran', '#Imine', '#Halogen']\n",
      "Top 20 features for mps_pred:\n",
      "['#Donor', '#Accept', 'SLogP', '#Ar-N', 'apol', '#R=R', '#O/#C', '#Ether', 'Vabc', '#ArHR', '#Bran', '#ArR', '#C', '#AlHR', '#Imine', '#SCR', '#Ring', '#SHR', '#Ketone', '#AlCR']\n",
      "Top 20 features for fps_pred:\n",
      "['#Accept', 'SLogP', '#Donor', '#C', '#O/#C', '#Ether', 'apol', '#R=R', '#Nitrile', '#Ar-N', '#AlHR', '#ArR', '#Imine', '#ArHR', 'Vabc', '#Ring', '#AlCR', '#C=O', '#Ester', '#SCR']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df2 = pd.read_csv(f'{input_file2}.csv').replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df1 = pd.read_csv(f'{input_file1}.csv')\n",
    "\n",
    "# Khởi tạo dictionary để lưu features\n",
    "final_features = {}\n",
    "\n",
    "for target in ['bps_pred', 'mps_pred', 'fps_pred']:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    \n",
    "    # 1. Feature Importance từ Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=7)\n",
    "    rf.fit(X, y)\n",
    "    rf_imp = pd.DataFrame({'feature': X.columns, 'RF_score': rf.feature_importances_})\n",
    "    # 1.5. Thêm XGBoost Feature Importance\n",
    "    xgb = XGBRegressor(random_state=7)\n",
    "    xgb.fit(X, y)\n",
    "    xgb_imp = pd.DataFrame({'feature': X.columns, 'XGB_score': xgb.feature_importances_})\n",
    "    # 2. SelectKBest với Mutual Info\n",
    "    selector = SelectKBest(mutual_info_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    skb_imp = pd.DataFrame({'feature': X.columns, 'SKB_score': selector.scores_})\n",
    "    \n",
    "    # 3. PCA Loadings\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=0.9999)\n",
    "    pca.fit(X_scaled)\n",
    "    pca_loadings = pd.DataFrame(pca.components_.T, index=X.columns).abs().sum(axis=1)\n",
    "    pca_imp = pd.DataFrame({'feature': pca_loadings.index, 'PCA_score': pca_loadings.values})\n",
    "    \n",
    "    # Kết hợp tất cả các phương pháp\n",
    "    combined = rf_imp.merge(skb_imp, on='feature').merge(pca_imp, on='feature').merge(xgb_imp, on='feature', how='left')\n",
    "    \n",
    "    # Tính rank cho từng phương pháp\n",
    "    for method in ['RF_score', 'SKB_score', 'PCA_score', 'XGB_score']:\n",
    "        combined[f'{method}_rank'] = combined[method].rank(ascending=False, method='dense')\n",
    "    \n",
    "    # Tính rank trung bình\n",
    "    combined['Avg_Rank'] = combined[['RF_score_rank', 'SKB_score_rank', 'PCA_score_rank', 'XGB_score_rank']].mean(axis=1)\n",
    "    \n",
    "    # Chọn top 20 features\n",
    "    top_20 = combined.sort_values('Avg_Rank').head(20)['feature'].tolist()\n",
    "    final_features[target] = top_20\n",
    "    print(f\"Top 20 features for {target}:\")\n",
    "    print(top_20)\n",
    "    \n",
    "\n",
    "# Lưu features vào list (ví dụ cho bps_pred)\n",
    "BPS_features = final_features['bps_pred']\n",
    "MPS_features = final_features['mps_pred']\n",
    "FPS_features = final_features['fps_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building models for bps_pred ===\n",
      "==================================================\n",
      "\n",
      "----- Optimizing XGBoost for BPS -----\n",
      "\n",
      "Best parameters for XGBoost:\n",
      "model__learning_rate: 0.06\n",
      "model__max_depth: 12\n",
      "model__n_estimators: 2000\n",
      "\n",
      "Evaluation Metrics on Test Set:\n",
      "R2 Score: 0.8796\n",
      "RMSE: 12.4634\n",
      "MAE: 9.4149\n",
      "MAPE: 2.0734%\n",
      "\n",
      "----- Model Comparison -----\n",
      "Model                 R2     RMSE      MAE     MAPE\n",
      "XGBoost           0.8796  12.4634   9.4149   2.0734%\n",
      "\n",
      "Best model for bps_pred is XGBoost (MAE = 9.4149)\n",
      "Pipeline(steps=[('model',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=None, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, gamma=None, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.06,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=12, max_leaves=None,\n",
      "                              min_child_weight=None, missing=nan,\n",
      "                              monotone_constraints=None, multi_strategy=None,\n",
      "                              n_estimators=2000, n_jobs=None,\n",
      "                              num_parallel_tree=None,\n",
      "                              objective='reg:absoluteerror', ...))])\n",
      "\n",
      "=== Building models for mps_pred ===\n",
      "==================================================\n",
      "\n",
      "----- Optimizing XGBoost for MPS -----\n",
      "\n",
      "Best parameters for XGBoost:\n",
      "model__learning_rate: 0.09\n",
      "model__max_depth: 12\n",
      "model__n_estimators: 750\n",
      "\n",
      "Evaluation Metrics on Test Set:\n",
      "R2 Score: 0.9132\n",
      "RMSE: 19.3584\n",
      "MAE: 14.2360\n",
      "MAPE: 5.3242%\n",
      "\n",
      "----- Model Comparison -----\n",
      "Model                 R2     RMSE      MAE     MAPE\n",
      "XGBoost           0.9132  19.3584  14.2360   5.3242%\n",
      "\n",
      "Best model for mps_pred is XGBoost (MAE = 14.2360)\n",
      "Pipeline(steps=[('model',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=None, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, gamma=None, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.09,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=12, max_leaves=None,\n",
      "                              min_child_weight=None, missing=nan,\n",
      "                              monotone_constraints=None, multi_strategy=None,\n",
      "                              n_estimators=750, n_jobs=None,\n",
      "                              num_parallel_tree=None,\n",
      "                              objective='reg:absoluteerror', ...))])\n",
      "\n",
      "=== Building models for fps_pred ===\n",
      "==================================================\n",
      "\n",
      "----- Optimizing XGBoost for FPS -----\n",
      "\n",
      "Best parameters for XGBoost:\n",
      "model__learning_rate: 0.06\n",
      "model__max_depth: 12\n",
      "model__n_estimators: 2000\n",
      "\n",
      "Evaluation Metrics on Test Set:\n",
      "R2 Score: 0.9381\n",
      "RMSE: 8.0622\n",
      "MAE: 6.0355\n",
      "MAPE: 1.7826%\n",
      "\n",
      "----- Model Comparison -----\n",
      "Model                 R2     RMSE      MAE     MAPE\n",
      "XGBoost           0.9381   8.0622   6.0355   1.7826%\n",
      "\n",
      "Best model for fps_pred is XGBoost (MAE = 6.0355)\n",
      "Pipeline(steps=[('model',\n",
      "                 XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "                              colsample_bylevel=None, colsample_bynode=None,\n",
      "                              colsample_bytree=None, device=None,\n",
      "                              early_stopping_rounds=None,\n",
      "                              enable_categorical=False, eval_metric=None,\n",
      "                              feature_types=None, gamma=None, grow_policy=None,\n",
      "                              importance_type=None,\n",
      "                              interaction_constraints=None, learning_rate=0.06,\n",
      "                              max_bin=None, max_cat_threshold=None,\n",
      "                              max_cat_to_onehot=None, max_delta_step=None,\n",
      "                              max_depth=12, max_leaves=None,\n",
      "                              min_child_weight=None, missing=nan,\n",
      "                              monotone_constraints=None, multi_strategy=None,\n",
      "                              n_estimators=2000, n_jobs=None,\n",
      "                              num_parallel_tree=None,\n",
      "                              objective='reg:absoluteerror', ...))])\n"
     ]
    }
   ],
   "source": [
    "def save_model(model_name, model_type, method):\n",
    "    pkl_filename = f'{model_type}_{type(model_name).__name__}_{method}.pkl'\n",
    "    with open(pkl_filename, 'wb') as file:  \n",
    "        pickle.dump(model_name, file)\n",
    "    with open(pkl_filename, 'rb') as file:  \n",
    "        saved_model = pickle.load(file)\n",
    "    print(saved_model)\n",
    "\n",
    "# Tính toán MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Giả sử df2 là dataframe chứa dữ liệu của bạn\n",
    "features = [col for col in df2.columns if col not in \n",
    "            ['canonical_smiles', 'mps_pred', 'bps_pred', 'fps_pred']]\n",
    "\n",
    "targets = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "target_features = {\n",
    "    'bps_pred': BPS_features,\n",
    "    'mps_pred': MPS_features,\n",
    "    'fps_pred': FPS_features\n",
    "}\n",
    "methods = ['BPS', 'MPS', 'FPS']\n",
    "cv = 5\n",
    "\n",
    "# Hàm để lấy feature importance\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "        importances = model.named_steps['model'].feature_importances_\n",
    "    elif hasattr(model.named_steps['model'], 'coef_'):\n",
    "        importances = model.named_steps['model'].coef_\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    feature_importance = pd.DataFrame({'feature': feature_names, \n",
    "                                     'importance': importances})\n",
    "    return feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Xây dựng mô hình cho từng target\n",
    "for i, target in enumerate(targets):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    selected_features = target_features[target]\n",
    "    X = df2[selected_features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df2[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=7)\n",
    "\n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__max_depth\": [20],\n",
    "        \"model__min_samples_leaf\": [1],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        # (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "    \"model__n_estimators\": [2000, 1000],\n",
    "    \"model__max_depth\": [8, 10, 12],\n",
    "    \"model__learning_rate\": [0.09, 0.06],\n",
    "    \"model__alpha\": [0, 0.1],            # L1 regularization\n",
    "    \"model__gamma\": [0, 0.1],          # Minimum loss reduction để tách nhánh\n",
    "    \"model__subsample\": [1.0, 0.8],    # Tỉ lệ mẫu dữ liệu ngẫu nhiên\n",
    "    \"model__colsample_bytree\": [0.8, 1.0],  # Tỉ lệ đặc trưng ngẫu nhiên\n",
    "    \"model__min_child_weight\": [3, 5]    # Số lượng mẫu tối thiểu ở lá\n",
    "}\n",
    "    \n",
    "    models = [\n",
    "        # ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {methods[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, \n",
    "                            scoring='neg_mean_absolute_error')\n",
    "        search.fit(X_train, y_train, model__eval_set=[(X_val, y_val)],  model__early_stopping_rounds=50,   model__verbose=False               \n",
    ")\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{methods[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', methods[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
