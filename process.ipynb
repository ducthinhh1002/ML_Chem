{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = \"QM9_129440_MLtraining\"\n",
    "input_file2 = \"QM9_49762_MLtraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "df1 = pd.read_csv(f'{input_file1}.csv')\n",
    "df2 = pd.read_csv(f'{input_file2}.csv')\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Remove infinite values\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "to_drop = ['canonical_smiles']  # Thêm các features khác nếu cần\n",
    "df2 = df2.drop(columns=to_drop)\n",
    "\n",
    "missing_threshold = 0.1\n",
    "missing_percent = df2.isnull().mean()\n",
    "to_drop = missing_percent[missing_percent > missing_threshold].index\n",
    "df2 = df2.drop(columns=to_drop)\n",
    "\n",
    "# Loại bỏ features có variance thấp\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.08)  # Điều chỉnh threshold\n",
    "selector.fit(df2.select_dtypes(include=['float64', 'int64']))\n",
    "low_variance_cols = df2.columns[~selector.get_support()]\n",
    "df2 = df2.drop(columns=low_variance_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, model_type, method):\n",
    "    pkl_filename = f'{model_type}_{type(model_name).__name__}_{method}.pkl'\n",
    "    with open(pkl_filename, 'wb') as file:  \n",
    "        pickle.dump(model_name, file)\n",
    "    with open(pkl_filename, 'rb') as file:  \n",
    "        saved_model = pickle.load(file)\n",
    "    print(saved_model)\n",
    "\n",
    "# Tính toán MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Giả sử df2 là dataframe chứa dữ liệu của bạn\n",
    "features = [col for col in df2.columns if col not in \n",
    "            ['canonical_smiles', 'mps_pred', 'bps_pred', 'fps_pred']]\n",
    "\n",
    "targets = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "methods = ['BPS', 'MPS', 'FPS']\n",
    "cv = 5\n",
    "\n",
    "# Hàm để lấy feature importance\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "        importances = model.named_steps['model'].feature_importances_\n",
    "    elif hasattr(model.named_steps['model'], 'coef_'):\n",
    "        importances = model.named_steps['model'].coef_\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    feature_importance = pd.DataFrame({'feature': feature_names, \n",
    "                                     'importance': importances})\n",
    "    return feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Xây dựng mô hình cho từng target\n",
    "for i, target in enumerate(targets):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    X = df2[features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df2[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "    \n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__max_depth\": [20],\n",
    "        \"model__min_samples_leaf\": [1],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        # (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "        \"model__n_estimators\": [2000, 1000, 750],\n",
    "        \"model__max_depth\": [8, 10, 12],\n",
    "        \"model__learning_rate\": [0.09, 0.06],\n",
    "    }\n",
    "    \n",
    "    models = [\n",
    "        # ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {methods[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, \n",
    "                            scoring='neg_mean_absolute_error')\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{methods[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', methods[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
