{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "df1 = pd.read_csv('QM9_129440_MLtraining.csv')\n",
    "df2 = pd.read_csv('QM9_49762_MLtraining.csv')\n",
    "df2 = df2.dropna()\n",
    "\n",
    "# Remove infinite values\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "to_drop = ['canonical_smiles']  # Thêm các features khác nếu cần\n",
    "df2 = df2.drop(columns=to_drop)\n",
    "\n",
    "missing_threshold = 0.4\n",
    "missing_percent = df2.isnull().mean()\n",
    "to_drop = missing_percent[missing_percent > missing_threshold].index\n",
    "df2 = df2.drop(columns=to_drop)\n",
    "\n",
    "# Loại bỏ features có variance thấp\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.08)  # Điều chỉnh threshold\n",
    "selector.fit(df2.select_dtypes(include=['float64', 'int64']))\n",
    "low_variance_cols = df2.columns[~selector.get_support()]\n",
    "df2 = df2.drop(columns=low_variance_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building models for bps_pred ===\n",
      "==================================================\n",
      "\n",
      "----- Optimizing Random Forest for BPS -----\n",
      "\n",
      "Best parameters for Random Forest:\n",
      "model__max_depth: 20\n",
      "model__min_samples_leaf: 6\n",
      "model__min_samples_split: 6\n",
      "model__n_estimators: 200\n",
      "\n",
      "Evaluation Metrics on Test Set:\n",
      "R2 Score: 0.8809\n",
      "RMSE: 12.3929\n",
      "MAE: 9.1277\n",
      "MAPE: 2.0122%\n",
      "\n",
      "Top 20 Important Features:\n",
      "  feature  importance\n",
      "  #Accept    0.307170\n",
      "   #Ether    0.095014\n",
      "       #C    0.084697\n",
      "     apol    0.080753\n",
      "    SLogP    0.080645\n",
      " #Nitrile    0.063126\n",
      "   #Donor    0.055659\n",
      "    #AlHR    0.030920\n",
      "     Vabc    0.028301\n",
      "    #Bran    0.025401\n",
      "   Radius    0.022323\n",
      "     #C=O    0.018308\n",
      "     #R=R    0.013486\n",
      "       #O    0.011405\n",
      "  #Ketone    0.010069\n",
      "    #Ring    0.009186\n",
      "      #SR    0.009150\n",
      "     #SCR    0.007841\n",
      " #Epoxide    0.006145\n",
      "#Aldehyde    0.005926\n",
      "\n",
      "----- Optimizing XGBoost for BPS -----\n",
      "\n",
      "Best parameters for XGBoost:\n",
      "model__colsample_bytree: 1.0\n",
      "model__learning_rate: 0.1\n",
      "model__max_depth: 12\n",
      "model__n_estimators: 200\n",
      "model__subsample: 1.0\n",
      "\n",
      "Evaluation Metrics on Test Set:\n",
      "R2 Score: 0.8968\n",
      "RMSE: 11.5392\n",
      "MAE: 8.5776\n",
      "MAPE: 1.8872%\n",
      "\n",
      "Top 20 Important Features:\n",
      " feature  importance\n",
      " #Accept    0.197387\n",
      "#Nitrile    0.191317\n",
      "    #ArR    0.108328\n",
      "  #Donor    0.057265\n",
      "  #Ether    0.048301\n",
      "   #ArHR    0.043417\n",
      "    #C=O    0.039946\n",
      "   #AlHR    0.034355\n",
      "    apol    0.026540\n",
      "  #Imine    0.021323\n",
      "    #SCR    0.017566\n",
      " #Ketone    0.017178\n",
      "     #SR    0.016535\n",
      "      #C    0.016293\n",
      "    #SHR    0.015345\n",
      "    #AlR    0.014822\n",
      "   #Ring    0.014287\n",
      "    Vabc    0.013611\n",
      "    #R=R    0.012422\n",
      "  Radius    0.012070\n",
      "\n",
      "----- Model Comparison -----\n",
      "Model                 R2     RMSE      MAE     MAPE\n",
      "Random Forest     0.8809  12.3929   9.1277   2.0122%\n",
      "XGBoost           0.8968  11.5392   8.5776   1.8872%\n",
      "\n",
      "Best model for bps_pred is XGBoost (MAE = 8.5776)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_model() missing 1 required positional argument: 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Lưu best model\u001b[39;00m\n\u001b[0;32m    139\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethods[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 140\u001b[0m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_model_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: save_model() missing 1 required positional argument: 'method'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def save_model(self, model_name, model_type, method):\n",
    "        pkl_filename= f'{model_type}_{type(model_name).__name__}_{method}.pkl'\n",
    "        with open(pkl_filename, 'wb') as file:  \n",
    "            pickle.dump(model_name, file)\n",
    "        with open(pkl_filename, 'rb') as file:  \n",
    "            saved_model = pickle.load(file)\n",
    "                \n",
    "        print(saved_model)\n",
    "# Tính toán MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Giả sử df2 là dataframe chứa dữ liệu của bạn\n",
    "features = [col for col in df2.columns if col not in \n",
    "            ['canonical_smiles', 'mps_pred', 'bps_pred', 'fps_pred']]\n",
    "\n",
    "targets = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "methods = ['BPS', 'MPS', 'FPS']\n",
    "cv = 5\n",
    "\n",
    "# Hàm để lấy feature importance\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "        importances = model.named_steps['model'].feature_importances_\n",
    "    elif hasattr(model.named_steps['model'], 'coef_'):\n",
    "        importances = model.named_steps['model'].coef_\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    feature_importance = pd.DataFrame({'feature': feature_names, \n",
    "                                     'importance': importances})\n",
    "    return feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Xây dựng mô hình cho từng target\n",
    "for i, target in enumerate(targets):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    X = df2[features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df2[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "    \n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [200, 300, 400],\n",
    "        \"model__max_depth\": [20, 40, 60],\n",
    "        \"model__min_samples_leaf\": [6, 8, 10],\n",
    "        \"model__min_samples_split\": [6, 8, 10],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "        \"model__n_estimators\": [200, 250, 300],\n",
    "        \"model__max_depth\": [12, 15, 18],\n",
    "        \"model__learning_rate\": [0.1, 0.05],\n",
    "        \"model__subsample\": [1.0, 0.8, 0.6],\n",
    "        \"model__colsample_bytree\": [1.0],\n",
    "    }\n",
    "    \n",
    "    models = [\n",
    "        ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {methods[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=cv, \n",
    "                            scoring='neg_mean_absolute_error')\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        # Lấy feature importance\n",
    "        feature_importance = get_feature_importance(best_model, features)\n",
    "        if feature_importance is not None:\n",
    "            print(\"\\nTop 20 Important Features:\")\n",
    "            print(feature_importance.head(20).to_string(index=False))\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{methods[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
