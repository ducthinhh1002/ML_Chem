{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = \"QM9_129440_MLtraining\"\n",
    "input_file2 = \"QM9_49762_MLtraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Đọc dữ liệu\n",
    "df2 = pd.read_csv(f'{input_file2}.csv').replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df1 = pd.read_csv(f'{input_file1}.csv')\n",
    "\n",
    "# Khởi tạo dictionary để lưu features\n",
    "final_features = {}\n",
    "\n",
    "for target in ['bps_pred', 'mps_pred', 'fps_pred']:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    \n",
    "    # 1. Feature Importance từ Random Forest\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=7)\n",
    "    rf.fit(X, y)\n",
    "    rf_imp = pd.DataFrame({'feature': X.columns, 'RF_score': rf.feature_importances_})\n",
    "    # 1.5. Thêm XGBoost Feature Importance\n",
    "    xgb = XGBRegressor(random_state=7)\n",
    "    xgb.fit(X, y)\n",
    "    xgb_imp = pd.DataFrame({'feature': X.columns, 'XGB_score': xgb.feature_importances_})\n",
    "    # 2. SelectKBest với Mutual Info\n",
    "    selector = SelectKBest(mutual_info_regression, k='all')\n",
    "    selector.fit(X, y)\n",
    "    skb_imp = pd.DataFrame({'feature': X.columns, 'SKB_score': selector.scores_})\n",
    "    \n",
    "    # 3. PCA Loadings\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    pca = PCA(n_components=0.9999)\n",
    "    pca.fit(X_scaled)\n",
    "    pca_loadings = pd.DataFrame(pca.components_.T, index=X.columns).abs().sum(axis=1)\n",
    "    pca_imp = pd.DataFrame({'feature': pca_loadings.index, 'PCA_score': pca_loadings.values})\n",
    "    \n",
    "    # Kết hợp tất cả các phương pháp\n",
    "    combined = rf_imp.merge(skb_imp, on='feature').merge(pca_imp, on='feature').merge(xgb_imp, on='feature', how='left')\n",
    "    \n",
    "    # Tính rank cho từng phương pháp\n",
    "    for method in ['RF_score', 'SKB_score', 'PCA_score', 'XGB_score']:\n",
    "        combined[f'{method}_rank'] = combined[method].rank(ascending=False, method='dense')\n",
    "    \n",
    "    # Tính rank trung bình\n",
    "    combined['Avg_Rank'] = combined[['RF_score_rank', 'SKB_score_rank', 'PCA_score_rank', 'XGB_score_rank']].mean(axis=1)\n",
    "    \n",
    "    # Chọn top 20 features\n",
    "    top_20 = combined.sort_values('Avg_Rank').head(20)['feature'].tolist()\n",
    "    final_features[target] = top_20\n",
    "    print(f\"Top 20 features for {target}:\")\n",
    "    print(top_20)\n",
    "    \n",
    "\n",
    "# Lưu features vào list (ví dụ cho bps_pred)\n",
    "BPS_features = final_features['bps_pred']\n",
    "MPS_features = final_features['mps_pred']\n",
    "FPS_features = final_features['fps_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, model_type, method):\n",
    "    pkl_filename = f'{model_type}_{type(model_name).__name__}_{method}.pkl'\n",
    "    with open(pkl_filename, 'wb') as file:  \n",
    "        pickle.dump(model_name, file)\n",
    "    with open(pkl_filename, 'rb') as file:  \n",
    "        saved_model = pickle.load(file)\n",
    "    print(saved_model)\n",
    "\n",
    "# Tính toán MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Giả sử df2 là dataframe chứa dữ liệu của bạn\n",
    "features = [col for col in df2.columns if col not in \n",
    "            ['canonical_smiles', 'mps_pred', 'bps_pred', 'fps_pred']]\n",
    "\n",
    "targets = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "target_features = {\n",
    "    'bps_pred': BPS_features,\n",
    "    'mps_pred': MPS_features,\n",
    "    'fps_pred': FPS_features\n",
    "}\n",
    "methods = ['BPS', 'MPS', 'FPS']\n",
    "cv = 5\n",
    "\n",
    "# Hàm để lấy feature importance\n",
    "def get_feature_importance(model, feature_names):\n",
    "    if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "        importances = model.named_steps['model'].feature_importances_\n",
    "    elif hasattr(model.named_steps['model'], 'coef_'):\n",
    "        importances = model.named_steps['model'].coef_\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    feature_importance = pd.DataFrame({'feature': feature_names, \n",
    "                                     'importance': importances})\n",
    "    return feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Xây dựng mô hình cho từng target\n",
    "for i, target in enumerate(targets):\n",
    "    print(f\"\\n=== Building models for {target} ===\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    selected_features = target_features[target]\n",
    "    X = df2[selected_features]\n",
    "    # Handle infinity values by replacing with mean\n",
    "    inf_mask = X.isin([np.inf, -np.inf])\n",
    "    if inf_mask.any().any():\n",
    "        X = X.replace([np.inf, -np.inf], np.nan)\n",
    "        X = X.fillna(X.mean())\n",
    "    y = df2[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "    \n",
    "    # 1. Pipeline và param grid cho Random Forest\n",
    "    rf_pipe = Pipeline([\n",
    "        (\"scaler\", MinMaxScaler()), \n",
    "        ('model', RandomForestRegressor(criterion='absolute_error', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        \"model__n_estimators\": [100],\n",
    "        \"model__max_depth\": [20],\n",
    "        \"model__min_samples_leaf\": [1],\n",
    "    }\n",
    "    \n",
    "    # 2. Pipeline và param grid cho XGBoost\n",
    "    xgb_pipe = Pipeline([\n",
    "        # (\"scaler\", MinMaxScaler()), \n",
    "        ('model', XGBRegressor(objective='reg:absoluteerror', random_state=7))\n",
    "    ])\n",
    "    \n",
    "    xgb_param_grid = {\n",
    "        \"model__n_estimators\": [2000, 1000, 750],\n",
    "        \"model__max_depth\": [8, 10, 12],\n",
    "        \"model__learning_rate\": [0.09, 0.06],\n",
    "    }\n",
    "    \n",
    "    models = [\n",
    "        # ('Random Forest', rf_pipe, rf_param_grid),\n",
    "        ('XGBoost', xgb_pipe, xgb_param_grid)\n",
    "    ]\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    for name, pipe, param_grid in models:\n",
    "        print(f'\\n----- Optimizing {name} for {methods[i]} -----')\n",
    "        search = GridSearchCV(pipe, param_grid, n_jobs=-1, \n",
    "                            scoring='neg_mean_absolute_error')\n",
    "        search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Tính các metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {name}:\")\n",
    "        for param, value in search.best_params_.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics on Test Set:\")\n",
    "        print(f\"R2 Score: {r2:.4f}\")\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MAPE: {mape:.4f}%\")\n",
    "        \n",
    "        best_models[name] = {\n",
    "            'model': best_model,\n",
    "            'metrics': {\n",
    "                'R2': r2,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae,\n",
    "                'MAPE': mape\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # So sánh kết quả tốt nhất giữa 2 mô hình\n",
    "    print('\\n----- Model Comparison -----')\n",
    "    print(f\"{'Model':<15} {'R2':>8} {'RMSE':>8} {'MAE':>8} {'MAPE':>8}\")\n",
    "    for name, result in best_models.items():\n",
    "        metrics = result['metrics']\n",
    "        print(f\"{name:<15} {metrics['R2']:8.4f} {metrics['RMSE']:8.4f} \" \n",
    "              f\"{metrics['MAE']:8.4f} {metrics['MAPE']:8.4f}%\")\n",
    "    \n",
    "    # Xác định best model dựa trên MAE\n",
    "    best_model_name = min(best_models.items(), \n",
    "                         key=lambda x: x[1]['metrics']['MAE'])[0]\n",
    "    print(f\"\\nBest model for {target} is {best_model_name} \"\n",
    "          f\"(MAE = {best_models[best_model_name]['metrics']['MAE']:.4f})\")\n",
    "    \n",
    "    # Lưu best model\n",
    "    model_name = f\"{methods[i]}_{best_model_name.replace(' ', '_')}\"\n",
    "    save_model(best_models[best_model_name]['model'], 'regression', methods[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
