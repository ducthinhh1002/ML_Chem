{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file1 = \"QM9_129440_MLtraining\"\n",
    "input_file2 = \"QM9_49762_MLtraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "df1 = pd.read_csv(f'{input_file1}.csv')\n",
    "df2 = pd.read_csv(f'{input_file2}.csv')\n",
    "print(df2.info())\n",
    "print(df2.describe())\n",
    "\n",
    "print(df2.isnull().sum().sort_values(ascending=False))\n",
    "df2 = df2.dropna()\n",
    "df2 = df2.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Phân phối target variables\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for i, target in enumerate(['bps_pred', 'mps_pred', 'fps_pred']):\n",
    "    sns.histplot(df2[target], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Phân phối của {target}')\n",
    "plt.show()\n",
    "\n",
    "# Phân phối các features numeric\n",
    "numeric_cols = df2.select_dtypes(include=['float64', 'int64']).columns\n",
    "df2[numeric_cols].hist(bins=30, figsize=(20, 15))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ma trận tương quan\n",
    "corr_matrix = df2.select_dtypes(include=['float64', 'int64']).corr()\n",
    "plt.figure(figsize=(20, 15))\n",
    "sns.heatmap(corr_matrix[(corr_matrix > 0.4) | (corr_matrix < -0.4)], \n",
    "            annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix (|corr| > 0.5)')\n",
    "plt.show()\n",
    "\n",
    "# Tương quan với target\n",
    "targets = ['bps_pred', 'mps_pred', 'fps_pred']\n",
    "for target in targets:\n",
    "    corr_with_target = df2.select_dtypes(include=['float64', 'int64']).corr()[target].sort_values(ascending=False)\n",
    "    print(f\"\\nTương quan với {target}:\")\n",
    "    print(corr_with_target[abs(corr_with_target) > 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frature importance từ mô hình\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Tính feature importance cho từng target\n",
    "for target in ['bps_pred', 'mps_pred', 'fps_pred']:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=7)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nFeature importance cho {target}:\")\n",
    "    print(importance.head(20))\n",
    "    \n",
    "    # Visualize top 20 features\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=importance.head(30))\n",
    "    plt.title(f'Top 20 Features for {target}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chọn feaatures bằng thống kê\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "\n",
    "for target in ['bps_pred', 'mps_pred', 'fps_pred']:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    \n",
    "    # Chọn top k features dựa trên mutual information\n",
    "    selector = SelectKBest(score_func=mutual_info_regression, k=20)\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "    scores = selector.scores_[selector.get_support()]\n",
    "    \n",
    "    print(f\"\\nTop features cho {target} (Mutual Info):\")\n",
    "    print(pd.DataFrame({'feature': selected_features, 'score': scores})\n",
    "          .sort_values('score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PCA để giảm chiều và chọn features quan trọng\n",
    "for target in ['bps_pred', 'mps_pred', 'fps_pred']:\n",
    "    X = df2.drop(columns=['bps_pred', 'mps_pred', 'fps_pred', 'canonical_smiles'])\n",
    "    y = df2[target]\n",
    "    \n",
    "    # Chuẩn hóa dữ liệu trước khi thực hiện PCA\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Thực hiện PCA\n",
    "    pca = PCA(n_components=0.9999)  # Giữ lại các thành phần giải thích 95% phương sai\n",
    "    pca_result = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # In ra số lượng thành phần được giữ lại\n",
    "    print(f\"\\nPCA cho {target}:\")\n",
    "    print(f\"Số lượng thành phần chính được giữ lại: {pca.n_components_}\")\n",
    "    print(f\"Tổng phương sai giải thích được: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "    \n",
    "    # Hiển thị tỷ lệ phương sai được giải thích bởi mỗi thành phần\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "             np.cumsum(pca.explained_variance_ratio_), 'r-')\n",
    "    plt.xlabel('Thành phần chính')\n",
    "    plt.ylabel('Tỷ lệ phương sai giải thích')\n",
    "    plt.title(f'Scree Plot cho {target}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Xác định các features quan trọng nhất thông qua PCA loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'PC{i+1}' for i in range(pca.n_components_)],\n",
    "        index=X.columns\n",
    "    )\n",
    "    \n",
    "    # Lấy top features có ảnh hưởng lớn nhất đến các principal components\n",
    "    abs_loadings = abs(loadings).sum(axis=1).sort_values(ascending=False)\n",
    "    print(\"\\nTop 20 features quan trọng nhất theo PCA:\")\n",
    "    print(abs_loadings.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
